---
title: "ENVS-193DS Final"
author: "Rebecca Martinez"
date: "June 12, 2025"
format: html
---

ðŸ’» [**GitHub Repository**](https://github.com/RebeccaLMartinez/ENVS-193DS_spring-2025_final)

```{r setup,  message=FALSE, warning=FALSE, error=FALSE}

# --- necessary packages (possibly more) ---

library(tidyverse)   # Basic necessity
library(here)        # File path management
library(janitor)     # Cleans names
library(readxl)      # Read Excel files
library(scales)      # Customize axis labels
library(ggeffects)   # For model predictions
library(ggthemes)
library(flextable)   # Creates tables 
library(rstatix)     # Easy statistical tests
library(effectsize)  # Calculate effect sizes
library(lubridate)   # To work with dates
library(paletteer)  # Color package

# --- sea surface temperature data ---

sst <- read_csv(here("data", "sst_update2023.csv"))  # SST data CSV file

```

# Problem 1. Research writing 

## a. Transparent statistical methods  

**In part 2**, average nitrogen loads across five different sources (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands), which suggests they used a one-way ANOVA, the standard method for comparing means across multiple categorical groups. The p-value of 0.02 indicates at least one group mean differs significantly from the others.  

Because no other details were provided, these are the most likely tests based on the language and p-values reported.  

## b. More information needed  

The test in part 2 looks like an ANOVA, which is good for comparing nitrogen load across sources. But to give more context, these could be added:

1. **Post-hoc test (like Tukeyâ€™s HSD)**. ANOVA tells us that at least one group is different, but not which ones. A post-hoc test helps identify which specific sources differ. 


## c. Suggestions for rewriting 






# Problem 2

## a. Cleaning and summarizing

Below you can find code to clean and summarize the 'sst' data set:

```{r cleaning data}


sst_clean <- sst |> # new df using sst data
  # Convert data types
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),   # Format date as YYYY-MM-DD
    site = as.character(site),                   # Make site a character
    latitude = as.numeric(latitude),             # Make latitude numeric
    longitude = as.numeric(longitude),           # Make longitude numeric
    temp = as.numeric(temp)                      # Make temp numeric
  ) |>

  # Create year and month columns
  mutate(
    year = factor(format(date, "%Y"), levels = as.character(2018:2023)),  # Year as factor
    month = factor(format(date, "%b"), levels = month.abb, ordered = TRUE)  # Ordered month names
  ) |>
 drop_na() |>  # Remove rows with na

  group_by(year, month) |>  # Group by year and month

  summarise(
    mean_monthly_sst = mean(temp),  # Calculate mean temp for each group
    .groups = "drop"                # Ungroup after summarizing
  )

```


```{r data structure}

slice_sample(   # Preview n=5 rows of new df
  sst_clean,
  n = 5)

str(sst_clean) # View structure of new df

```

## b. Visualize the data


```{r line plot, warning=FALSE, error=FALSE}

ggplot(sst_clean, aes(x = month, y = mean_monthly_sst, group = factor(year), color = factor(year))) +
  geom_line(size = 0.8) +  # Add lines 
  geom_point() +  # Add points
  scale_color_paletteer_d("colRoz::sky", name = "Year") +  #  Discrete palette with gradient-like blue tones by year
      # Axes labels
  labs(
    y = "Mean monthly sea surface temperature (Â°C)",  # Y-axis label
    x = "Month"  # X-axis label
  ) +

  # Apply a clean black-and-white theme and customize appearance
  theme_bw(base_size = 12) +  # Use a simple, readable theme
  theme(
    panel.grid = element_blank(),  # Remove default gridlines
    legend.position = c(0.1, 0.75),  # Position legend inside plot
    axis.title.x = element_text(size = 14),  # Larger x-axis title
    axis.title.y = element_text(size = 14)   # Larger y-axis title
  )


```















